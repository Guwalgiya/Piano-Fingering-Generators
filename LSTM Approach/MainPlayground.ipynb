{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import system dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../')\n",
    "import shutil\n",
    "import statistics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import custom packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "music21: Certain music21 functions might need the optional package matplotlib;\n",
      "                  if you run into errors, install it by following the instructions at\n",
      "                  http://mit.edu/music21/doc/installing/installAdditional.html\n"
     ]
    }
   ],
   "source": [
    "from Utils import shuffleDataset, SplitJPData, saveToPickle, loadFromPickle, SplitChopinData, SplitMozartData, SplitBachData\n",
    "from JPDataPreProcessing import toVectorTrainFormat, toVectorTestFormat, toInterleavedTrainFormat, toVectorFutureTrainFormat\n",
    "from TrainModel import trainModel\n",
    "from TestVectorModel import loadModel, testVecModelSave, testVecModelEval\n",
    "from EvaluateJPMethod import getScoresForDL, getScoresForHmm\n",
    "\n",
    "from ReferenceHMM import GetESTFingering\n",
    "from parameters import DATA_DIR, HMM_RES_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Dataset According to Composer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files, test_files, hmm_res_files = SplitBachData(DATA_DIR)\n",
    "# train_files, test_files, hmm_res_files = SplitMozartData(DATA_DIR)\n",
    "# train_files, test_files, hmm_res_files = SplitBachData(DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train all 3 model of reference HMM with the data splited above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../ReferenceHMM')\n",
    "GetESTFingering.prepareInputList(train_files)\n",
    "GetESTFingering.trainHmm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run trained HMM model, change GetESTFingering.FHMMx to swith models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filenames = GetESTFingering.getFormattedTestFilenames(test_files)\n",
    "GetESTFingering.runHmm(test_filenames, GetESTFingering.FHMM1, default=False)\n",
    "GetESTFingering.convertToCsv(input_dir='ESTResults/selfTrained/'+GetESTFingering.FHMM1+'/', output_dir='JPESTResults/selfTrained/'+GetESTFingering.FHMM1+'/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "move the files the to correct folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(HMM_RES_DIR + GetESTFingering.FHMM1):\n",
    "    shutil.rmtree(HMM_RES_DIR + GetESTFingering.FHMM1)\n",
    "shutil.move('JPESTResults/selfTrained/' + GetESTFingering.FHMM1, HMM_RES_DIR)\n",
    "os.chdir('../LSTM Approach')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate hmm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total mean: \n",
      "M_GEN:  0.5724991389949875\n",
      "M_HIGH:  0.6403457066119016\n",
      "M_SOFT:  0.8447943944896392\n"
     ]
    }
   ],
   "source": [
    "getScoresForHmm(test_files, hmm_res_files, GetESTFingering.FHMM1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train DeepLearning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_list, train_label_list = toVectorFutureTrainFormat(train_files, DATA_DIR)\n",
    "trainModel(train_input_list, train_label_list, num_epochs=8, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eval DeepLearning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = loadModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of mulitple fingering for a single piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getScoresForDL(test_files, hmm_res_files, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
